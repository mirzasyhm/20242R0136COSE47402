{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMDkMeHdkrV6",
        "outputId": "bd09ad3e-70a1-409d-9beb-ccab0f96d278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mirzasyhm/20242R0136COSE47402.git\n",
        "%cd 20242R0136COSE47402/COSE2024_FinalProject\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "!mkdir datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L-Crs5qlFjG",
        "outputId": "0d2960e9-c029-4d40-be2b-c151a3e132f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '20242R0136COSE47402'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Total 154 (delta 0), reused 0 (delta 0), pack-reused 154 (from 1)\u001b[K\n",
            "Receiving objects: 100% (154/154), 112.08 MiB | 62.21 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n",
            "/content/20242R0136COSE47402/20242R0136COSE47402/COSE2024_FinalProject\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.46.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (11.0.0)\n",
            "Collecting pytesseract (from -r requirements.txt (line 5))\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.5.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.6.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (0.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (3.5.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->-r requirements.txt (line 8)) (2024.8.30)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->-r requirements.txt (line 8)) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->-r requirements.txt (line 8)) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->-r requirements.txt (line 8)) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->-r requirements.txt (line 8)) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->-r requirements.txt (line 8)) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.10)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Tesseract OCR\n",
        "!sudo apt update\n",
        "!sudo apt install tesseract-ocr -y\n",
        "\n",
        "!tesseract --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-zp5Cd_lWrk",
        "outputId": "4c856a01-a9a6-4a3f-8d0a-eff125a80584"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [\u001b[0m\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [\u001b[0m\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [\u001b[0m\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,190 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,624 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,525 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [53.3 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,514 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,446 kB]\n",
            "Hit:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
            "Hit:18 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:19 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [35.0 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,225 kB]\n",
            "Fetched 24.2 MB in 2s (12.4 MB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "51 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 51 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 0s (11.9 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "tesseract 4.1.1\n",
            " leptonica-1.82.0\n",
            "  libgif 5.1.9 : libjpeg 8d (libjpeg-turbo 2.1.1) : libpng 1.6.37 : libtiff 4.3.0 : zlib 1.2.11 : libwebp 1.2.2 : libopenjp2 2.4.0\n",
            " Found AVX512BW\n",
            " Found AVX512F\n",
            " Found AVX2\n",
            " Found AVX\n",
            " Found FMA\n",
            " Found SSE\n",
            " Found libarchive 3.6.0 zlib/1.2.11 liblzma/5.2.5 bz2lib/1.0.8 liblz4/1.9.3 libzstd/1.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"williamscott701/memotion-dataset-7k\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "!mv /root/.cache/kagglehub/datasets/williamscott701/memotion-dataset-7k/versions/1/memotion_dataset_7k/* datasets/\n",
        "\n",
        "path = kagglehub.dataset_download(\"parthplc/facebook-hateful-meme-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "!mv /root/.cache/kagglehub/datasets/parthplc/facebook-hateful-meme-dataset/versions/1/data/* datasets/\n",
        "!ls datasets/\n",
        "%cd src/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmFVlYbyqznJ",
        "outputId": "94773573-5500-4fe0-e952-0ae1ca177a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/williamscott701/memotion-dataset-7k?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 695M/695M [00:04<00:00, 154MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/williamscott701/memotion-dataset-7k/versions/1\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/parthplc/facebook-hateful-meme-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.35G/3.35G [00:20<00:00, 177MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/parthplc/facebook-hateful-meme-dataset/versions/1\n",
            "dev.jsonl  labels.csv\t     LICENSE.txt    reference_df_pickle  train.jsonl\n",
            "images\t   labels_pd_pickle  README.md\t    reference.xlsx\n",
            "img\t   labels.xlsx\t     reference.csv  test.jsonl\n",
            "/content/HateMeme/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python split_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoG_zDK3NS5a",
        "outputId": "fa2d7c48-d26b-469f-896a-71ae515b4fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split completed:\n",
            " - Train set: 6799 samples\n",
            " - Validation set: 851 samples\n",
            " - Test set: 850 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_baseline.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxFt2OyERU40",
        "outputId": "b9755723-8055-4e9f-92ba-acb5bae9ef1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-04 08:17:03.400694: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-04 08:17:03.418656: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-04 08:17:03.439745: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-04 08:17:03.446124: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-04 08:17:03.461576: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-04 08:17:04.617473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using device: cuda\n",
            "Baseline CLIP-Only Classifier - Epoch 1/50 | Train Loss: 0.6455\n",
            "Validation - Epoch 1/50 | Accuracy: 0.6475 | Precision: 0.7273 | Recall: 0.0262 | F1-Score: 0.0506\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 2/50 | Train Loss: 0.6119\n",
            "Validation - Epoch 2/50 | Accuracy: 0.6651 | Precision: 0.7632 | Recall: 0.0951 | F1-Score: 0.1691\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 3/50 | Train Loss: 0.5849\n",
            "Validation - Epoch 3/50 | Accuracy: 0.6392 | Precision: 0.4976 | Recall: 0.6885 | F1-Score: 0.5777\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 4/50 | Train Loss: 0.5366\n",
            "Validation - Epoch 4/50 | Accuracy: 0.6992 | Precision: 0.5793 | Recall: 0.5869 | F1-Score: 0.5831\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 5/50 | Train Loss: 0.5061\n",
            "Validation - Epoch 5/50 | Accuracy: 0.6769 | Precision: 0.5439 | Recall: 0.6098 | F1-Score: 0.5750\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 6/50 | Train Loss: 0.4779\n",
            "Validation - Epoch 6/50 | Accuracy: 0.6710 | Precision: 0.5436 | Recall: 0.5115 | F1-Score: 0.5270\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 7/50 | Train Loss: 0.4446\n",
            "Validation - Epoch 7/50 | Accuracy: 0.6616 | Precision: 0.5333 | Recall: 0.4459 | F1-Score: 0.4857\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 8/50 | Train Loss: 0.4257\n",
            "Validation - Epoch 8/50 | Accuracy: 0.6769 | Precision: 0.5708 | Recall: 0.3967 | F1-Score: 0.4681\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 9/50 | Train Loss: 0.3957\n",
            "Validation - Epoch 9/50 | Accuracy: 0.6334 | Precision: 0.4892 | Recall: 0.5213 | F1-Score: 0.5048\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 10/50 | Train Loss: 0.3759\n",
            "Validation - Epoch 10/50 | Accuracy: 0.6475 | Precision: 0.5117 | Recall: 0.3574 | F1-Score: 0.4208\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 11/50 | Train Loss: 0.3545\n",
            "Validation - Epoch 11/50 | Accuracy: 0.6251 | Precision: 0.4727 | Recall: 0.3967 | F1-Score: 0.4314\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 12/50 | Train Loss: 0.3388\n",
            "Validation - Epoch 12/50 | Accuracy: 0.6240 | Precision: 0.4689 | Recall: 0.3705 | F1-Score: 0.4139\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 13/50 | Train Loss: 0.3157\n",
            "Validation - Epoch 13/50 | Accuracy: 0.6052 | Precision: 0.4452 | Recall: 0.4131 | F1-Score: 0.4286\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 14/50 | Train Loss: 0.2925\n",
            "Validation - Epoch 14/50 | Accuracy: 0.6251 | Precision: 0.4693 | Recall: 0.3508 | F1-Score: 0.4015\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 15/50 | Train Loss: 0.2804\n",
            "Validation - Epoch 15/50 | Accuracy: 0.6169 | Precision: 0.4564 | Recall: 0.3607 | F1-Score: 0.4029\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 16/50 | Train Loss: 0.2739\n",
            "Validation - Epoch 16/50 | Accuracy: 0.5911 | Precision: 0.4322 | Recall: 0.4492 | F1-Score: 0.4405\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 17/50 | Train Loss: 0.2715\n",
            "Validation - Epoch 17/50 | Accuracy: 0.6075 | Precision: 0.4422 | Recall: 0.3639 | F1-Score: 0.3993\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 18/50 | Train Loss: 0.2730\n",
            "Validation - Epoch 18/50 | Accuracy: 0.6122 | Precision: 0.4468 | Recall: 0.3443 | F1-Score: 0.3889\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 19/50 | Train Loss: 0.2539\n",
            "Validation - Epoch 19/50 | Accuracy: 0.5699 | Precision: 0.4141 | Recall: 0.4820 | F1-Score: 0.4455\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 20/50 | Train Loss: 0.2402\n",
            "Validation - Epoch 20/50 | Accuracy: 0.5723 | Precision: 0.4130 | Recall: 0.4590 | F1-Score: 0.4348\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 21/50 | Train Loss: 0.2273\n",
            "Validation - Epoch 21/50 | Accuracy: 0.5476 | Precision: 0.4015 | Recall: 0.5344 | F1-Score: 0.4585\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 22/50 | Train Loss: 0.2223\n",
            "Validation - Epoch 22/50 | Accuracy: 0.6099 | Precision: 0.4453 | Recall: 0.3607 | F1-Score: 0.3986\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 23/50 | Train Loss: 0.2236\n",
            "Validation - Epoch 23/50 | Accuracy: 0.6134 | Precision: 0.4444 | Recall: 0.3148 | F1-Score: 0.3685\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 24/50 | Train Loss: 0.2082\n",
            "Validation - Epoch 24/50 | Accuracy: 0.5405 | Precision: 0.3892 | Recall: 0.4951 | F1-Score: 0.4358\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 25/50 | Train Loss: 0.1939\n",
            "Validation - Epoch 25/50 | Accuracy: 0.5582 | Precision: 0.4043 | Recall: 0.4918 | F1-Score: 0.4438\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 26/50 | Train Loss: 0.1934\n",
            "Validation - Epoch 26/50 | Accuracy: 0.6052 | Precision: 0.4357 | Recall: 0.3443 | F1-Score: 0.3846\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 27/50 | Train Loss: 0.1993\n",
            "Validation - Epoch 27/50 | Accuracy: 0.5922 | Precision: 0.4255 | Recall: 0.3934 | F1-Score: 0.4089\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 28/50 | Train Loss: 0.1981\n",
            "Validation - Epoch 28/50 | Accuracy: 0.5546 | Precision: 0.3879 | Recall: 0.4197 | F1-Score: 0.4031\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 29/50 | Train Loss: 0.1942\n",
            "Validation - Epoch 29/50 | Accuracy: 0.5570 | Precision: 0.4011 | Recall: 0.4787 | F1-Score: 0.4365\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 30/50 | Train Loss: 0.1951\n",
            "Validation - Epoch 30/50 | Accuracy: 0.5793 | Precision: 0.4120 | Recall: 0.4066 | F1-Score: 0.4092\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 31/50 | Train Loss: 0.1919\n",
            "Validation - Epoch 31/50 | Accuracy: 0.5652 | Precision: 0.4006 | Recall: 0.4295 | F1-Score: 0.4146\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 32/50 | Train Loss: 0.1803\n",
            "Validation - Epoch 32/50 | Accuracy: 0.5758 | Precision: 0.4041 | Recall: 0.3869 | F1-Score: 0.3953\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 33/50 | Train Loss: 0.1748\n",
            "Validation - Epoch 33/50 | Accuracy: 0.5652 | Precision: 0.3934 | Recall: 0.3934 | F1-Score: 0.3934\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 34/50 | Train Loss: 0.1706\n",
            "Validation - Epoch 34/50 | Accuracy: 0.5464 | Precision: 0.3859 | Recall: 0.4492 | F1-Score: 0.4152\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 35/50 | Train Loss: 0.1656\n",
            "Validation - Epoch 35/50 | Accuracy: 0.5617 | Precision: 0.3963 | Recall: 0.4262 | F1-Score: 0.4107\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 36/50 | Train Loss: 0.1685\n",
            "Validation - Epoch 36/50 | Accuracy: 0.5206 | Precision: 0.3696 | Recall: 0.4787 | F1-Score: 0.4171\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 37/50 | Train Loss: 0.1673\n",
            "Validation - Epoch 37/50 | Accuracy: 0.5734 | Precision: 0.4007 | Recall: 0.3836 | F1-Score: 0.3920\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 38/50 | Train Loss: 0.1737\n",
            "Validation - Epoch 38/50 | Accuracy: 0.5253 | Precision: 0.3598 | Recall: 0.4164 | F1-Score: 0.3860\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 39/50 | Train Loss: 0.1742\n",
            "Validation - Epoch 39/50 | Accuracy: 0.5593 | Precision: 0.3913 | Recall: 0.4131 | F1-Score: 0.4019\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 40/50 | Train Loss: 0.1606\n",
            "Validation - Epoch 40/50 | Accuracy: 0.5229 | Precision: 0.3653 | Recall: 0.4492 | F1-Score: 0.4029\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 41/50 | Train Loss: 0.1529\n",
            "Validation - Epoch 41/50 | Accuracy: 0.5276 | Precision: 0.3634 | Recall: 0.4230 | F1-Score: 0.3909\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 42/50 | Train Loss: 0.1524\n",
            "Validation - Epoch 42/50 | Accuracy: 0.5288 | Precision: 0.3674 | Recall: 0.4361 | F1-Score: 0.3988\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 43/50 | Train Loss: 0.1454\n",
            "Validation - Epoch 43/50 | Accuracy: 0.5605 | Precision: 0.3789 | Recall: 0.3541 | F1-Score: 0.3661\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 44/50 | Train Loss: 0.1414\n",
            "Validation - Epoch 44/50 | Accuracy: 0.5499 | Precision: 0.3892 | Recall: 0.4492 | F1-Score: 0.4170\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 45/50 | Train Loss: 0.1385\n",
            "Validation - Epoch 45/50 | Accuracy: 0.5311 | Precision: 0.3672 | Recall: 0.4262 | F1-Score: 0.3945\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 46/50 | Train Loss: 0.1335\n",
            "Validation - Epoch 46/50 | Accuracy: 0.5441 | Precision: 0.3584 | Recall: 0.3443 | F1-Score: 0.3512\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 47/50 | Train Loss: 0.1307\n",
            "Validation - Epoch 47/50 | Accuracy: 0.5311 | Precision: 0.3737 | Recall: 0.4557 | F1-Score: 0.4106\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 48/50 | Train Loss: 0.1296\n",
            "Validation - Epoch 48/50 | Accuracy: 0.5429 | Precision: 0.3765 | Recall: 0.4197 | F1-Score: 0.3969\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 49/50 | Train Loss: 0.1206\n",
            "Validation - Epoch 49/50 | Accuracy: 0.5300 | Precision: 0.3747 | Recall: 0.4656 | F1-Score: 0.4152\n",
            "\n",
            "Baseline CLIP-Only Classifier - Epoch 50/50 | Train Loss: 0.1323\n",
            "Validation - Epoch 50/50 | Accuracy: 0.5182 | Precision: 0.3562 | Recall: 0.4262 | F1-Score: 0.3881\n",
            "\n",
            "Baseline CLIP-Only Classifier trained and saved.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_baseline.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDjgL57CRaij",
        "outputId": "b177474e-c858-4225-e9ce-1aa0751a6f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-04 08:49:44.406047: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-04 08:49:44.423443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-04 08:49:44.444301: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-04 08:49:44.450610: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-04 08:49:44.465541: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-04 08:49:45.637400: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using device: cuda\n",
            "/content/HateMeme/src/test_baseline.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  clip_only_classifier.load_state_dict(torch.load('models/clip_only_classifier.pth', map_location=device))\n",
            "Baseline CLIP-Only Classifier Evaluation | Accuracy: 0.5553 | Precision: 0.4037 | Recall: 0.5016 | F1-Score: 0.4474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xoD7ivK2-Qu",
        "outputId": "b61ee0e8-0ea9-4527-fa31-58ce939d003d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-04 08:49:59.482817: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-04 08:49:59.500571: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-04 08:49:59.521511: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-04 08:49:59.527858: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-04 08:49:59.542842: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-04 08:50:00.717427: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using device: cuda\n",
            "Dropped 5 rows due to NaN in 'text_corrected'.\n",
            "Dropped 0 rows due to NaN in 'text_corrected'.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Sarcasm Detector - Epoch 1/3 | Loss: 0.0153\n",
            "Sarcasm Detector - Epoch 2/3 | Loss: 0.0001\n",
            "Sarcasm Detector - Epoch 3/3 | Loss: 0.0000\n",
            "Sarcasm Detector trained and saved.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/content/HateMeme/src/train.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sarcasm_detector.load_state_dict(torch.load('roberta_sarcasm_detector.pth', map_location=device))\n",
            "Epoch 1/50 | Train Loss: 0.6498 | Val Loss: 0.6294 | Accuracy: 0.6416 | Precision: 0.0000 | Recall: 0.0000 | F1-Score: 0.0000\n",
            "Epoch 2/50 | Train Loss: 0.6145 | Val Loss: 0.5972 | Accuracy: 0.7203 | Precision: 0.6450 | Recall: 0.4885 | F1-Score: 0.5560\n",
            "Epoch 3/50 | Train Loss: 0.5714 | Val Loss: 0.5983 | Accuracy: 0.6992 | Precision: 0.5842 | Recall: 0.5574 | F1-Score: 0.5705\n",
            "Epoch 4/50 | Train Loss: 0.5388 | Val Loss: 0.6484 | Accuracy: 0.6592 | Precision: 0.5216 | Recall: 0.5934 | F1-Score: 0.5552\n",
            "Epoch 5/50 | Train Loss: 0.5220 | Val Loss: 0.6410 | Accuracy: 0.6675 | Precision: 0.5364 | Recall: 0.5311 | F1-Score: 0.5338\n",
            "Epoch 6/50 | Train Loss: 0.5069 | Val Loss: 0.6760 | Accuracy: 0.6404 | Precision: 0.4986 | Recall: 0.6033 | F1-Score: 0.5460\n",
            "Epoch 7/50 | Train Loss: 0.4805 | Val Loss: 0.6796 | Accuracy: 0.6827 | Precision: 0.5585 | Recall: 0.5475 | F1-Score: 0.5530\n",
            "Epoch 8/50 | Train Loss: 0.4838 | Val Loss: 0.6561 | Accuracy: 0.6416 | Precision: 0.0000 | Recall: 0.0000 | F1-Score: 0.0000\n",
            "Epoch 9/50 | Train Loss: 0.4997 | Val Loss: 0.7060 | Accuracy: 0.6580 | Precision: 0.5210 | Recall: 0.5705 | F1-Score: 0.5446\n",
            "Epoch 10/50 | Train Loss: 0.4560 | Val Loss: 0.6997 | Accuracy: 0.6498 | Precision: 0.5097 | Recall: 0.6000 | F1-Score: 0.5512\n",
            "Epoch 11/50 | Train Loss: 0.4245 | Val Loss: 0.7553 | Accuracy: 0.6498 | Precision: 0.5101 | Recall: 0.5803 | F1-Score: 0.5429\n",
            "Epoch 12/50 | Train Loss: 0.4025 | Val Loss: 0.7764 | Accuracy: 0.6334 | Precision: 0.4904 | Recall: 0.5836 | F1-Score: 0.5329\n",
            "Epoch 13/50 | Train Loss: 0.3865 | Val Loss: 0.7893 | Accuracy: 0.6298 | Precision: 0.4854 | Recall: 0.5443 | F1-Score: 0.5131\n",
            "Epoch 14/50 | Train Loss: 0.3630 | Val Loss: 0.8360 | Accuracy: 0.6381 | Precision: 0.4947 | Recall: 0.4557 | F1-Score: 0.4744\n",
            "Epoch 15/50 | Train Loss: 0.3301 | Val Loss: 0.8952 | Accuracy: 0.6216 | Precision: 0.4772 | Recall: 0.5836 | F1-Score: 0.5251\n",
            "Epoch 16/50 | Train Loss: 0.3088 | Val Loss: 1.0616 | Accuracy: 0.6087 | Precision: 0.4600 | Recall: 0.5279 | F1-Score: 0.4916\n",
            "Epoch 17/50 | Train Loss: 0.2955 | Val Loss: 1.0412 | Accuracy: 0.6416 | Precision: 0.5000 | Recall: 0.4361 | F1-Score: 0.4658\n",
            "Epoch 18/50 | Train Loss: 0.2742 | Val Loss: 1.0716 | Accuracy: 0.5958 | Precision: 0.4485 | Recall: 0.5574 | F1-Score: 0.4971\n",
            "Epoch 19/50 | Train Loss: 0.2639 | Val Loss: 1.1013 | Accuracy: 0.6228 | Precision: 0.4699 | Recall: 0.4098 | F1-Score: 0.4378\n",
            "Epoch 20/50 | Train Loss: 0.2554 | Val Loss: 1.1215 | Accuracy: 0.6110 | Precision: 0.4542 | Recall: 0.4230 | F1-Score: 0.4380\n",
            "Epoch 21/50 | Train Loss: 0.2403 | Val Loss: 1.1862 | Accuracy: 0.6228 | Precision: 0.4633 | Recall: 0.3311 | F1-Score: 0.3862\n",
            "Epoch 22/50 | Train Loss: 0.2309 | Val Loss: 1.2255 | Accuracy: 0.5864 | Precision: 0.4307 | Recall: 0.4787 | F1-Score: 0.4534\n",
            "Epoch 23/50 | Train Loss: 0.2301 | Val Loss: 1.2481 | Accuracy: 0.6357 | Precision: 0.4883 | Recall: 0.3410 | F1-Score: 0.4015\n",
            "Epoch 24/50 | Train Loss: 0.2198 | Val Loss: 1.2689 | Accuracy: 0.6240 | Precision: 0.4723 | Recall: 0.4197 | F1-Score: 0.4444\n",
            "Epoch 25/50 | Train Loss: 0.2104 | Val Loss: 1.2651 | Accuracy: 0.6157 | Precision: 0.4673 | Recall: 0.5148 | F1-Score: 0.4899\n",
            "Epoch 26/50 | Train Loss: 0.2114 | Val Loss: 1.3464 | Accuracy: 0.6087 | Precision: 0.4533 | Recall: 0.4459 | F1-Score: 0.4496\n",
            "Epoch 27/50 | Train Loss: 0.2071 | Val Loss: 1.4534 | Accuracy: 0.5640 | Precision: 0.4179 | Recall: 0.5508 | F1-Score: 0.4752\n",
            "Epoch 28/50 | Train Loss: 0.2027 | Val Loss: 1.2836 | Accuracy: 0.6334 | Precision: 0.4836 | Recall: 0.3377 | F1-Score: 0.3977\n",
            "Epoch 29/50 | Train Loss: 0.1977 | Val Loss: 1.5613 | Accuracy: 0.5934 | Precision: 0.4402 | Recall: 0.4951 | F1-Score: 0.4660\n",
            "Epoch 30/50 | Train Loss: 0.2004 | Val Loss: 1.6316 | Accuracy: 0.6087 | Precision: 0.4444 | Recall: 0.3672 | F1-Score: 0.4022\n",
            "Epoch 31/50 | Train Loss: 0.1986 | Val Loss: 1.4085 | Accuracy: 0.5441 | Precision: 0.4063 | Recall: 0.5902 | F1-Score: 0.4813\n",
            "Epoch 32/50 | Train Loss: 0.1878 | Val Loss: 1.6667 | Accuracy: 0.5417 | Precision: 0.4027 | Recall: 0.5770 | F1-Score: 0.4744\n",
            "Epoch 33/50 | Train Loss: 0.1919 | Val Loss: 1.6914 | Accuracy: 0.6146 | Precision: 0.4534 | Recall: 0.3672 | F1-Score: 0.4058\n",
            "Epoch 34/50 | Train Loss: 0.1932 | Val Loss: 1.5419 | Accuracy: 0.6416 | Precision: 0.5000 | Recall: 0.3213 | F1-Score: 0.3912\n",
            "Epoch 35/50 | Train Loss: 0.1892 | Val Loss: 1.5834 | Accuracy: 0.6263 | Precision: 0.4677 | Recall: 0.3082 | F1-Score: 0.3715\n",
            "Epoch 36/50 | Train Loss: 0.1937 | Val Loss: 1.4189 | Accuracy: 0.5582 | Precision: 0.4176 | Recall: 0.5902 | F1-Score: 0.4891\n",
            "Epoch 37/50 | Train Loss: 0.2000 | Val Loss: 1.4124 | Accuracy: 0.6263 | Precision: 0.4663 | Recall: 0.2951 | F1-Score: 0.3614\n",
            "Epoch 38/50 | Train Loss: 0.1905 | Val Loss: 1.6047 | Accuracy: 0.6263 | Precision: 0.4670 | Recall: 0.3016 | F1-Score: 0.3665\n",
            "Epoch 39/50 | Train Loss: 0.1895 | Val Loss: 1.6284 | Accuracy: 0.6322 | Precision: 0.4806 | Recall: 0.3246 | F1-Score: 0.3875\n",
            "Epoch 40/50 | Train Loss: 0.1851 | Val Loss: 1.5644 | Accuracy: 0.5817 | Precision: 0.4215 | Recall: 0.4492 | F1-Score: 0.4349\n",
            "Epoch 41/50 | Train Loss: 0.1797 | Val Loss: 1.7793 | Accuracy: 0.5664 | Precision: 0.4096 | Recall: 0.4754 | F1-Score: 0.4401\n",
            "Epoch 42/50 | Train Loss: 0.1801 | Val Loss: 1.6603 | Accuracy: 0.5159 | Precision: 0.3741 | Recall: 0.5213 | F1-Score: 0.4356\n",
            "Epoch 43/50 | Train Loss: 0.1804 | Val Loss: 1.8505 | Accuracy: 0.5570 | Precision: 0.3902 | Recall: 0.4197 | F1-Score: 0.4044\n",
            "Epoch 44/50 | Train Loss: 0.1851 | Val Loss: 1.7602 | Accuracy: 0.6251 | Precision: 0.4657 | Recall: 0.3115 | F1-Score: 0.3733\n",
            "Epoch 45/50 | Train Loss: 0.1741 | Val Loss: 1.8189 | Accuracy: 0.5558 | Precision: 0.3954 | Recall: 0.4525 | F1-Score: 0.4220\n",
            "Epoch 46/50 | Train Loss: 0.1772 | Val Loss: 1.6616 | Accuracy: 0.5535 | Precision: 0.4026 | Recall: 0.5082 | F1-Score: 0.4493\n",
            "Epoch 47/50 | Train Loss: 0.1702 | Val Loss: 1.9037 | Accuracy: 0.5452 | Precision: 0.3943 | Recall: 0.5016 | F1-Score: 0.4416\n",
            "Epoch 48/50 | Train Loss: 0.1703 | Val Loss: 2.0438 | Accuracy: 0.5288 | Precision: 0.3750 | Recall: 0.4721 | F1-Score: 0.4180\n",
            "Epoch 49/50 | Train Loss: 0.1732 | Val Loss: 2.0284 | Accuracy: 0.5676 | Precision: 0.3981 | Recall: 0.4033 | F1-Score: 0.4007\n",
            "Epoch 50/50 | Train Loss: 0.1747 | Val Loss: 1.6107 | Accuracy: 0.5088 | Precision: 0.3736 | Recall: 0.5475 | F1-Score: 0.4441\n",
            "Hateful Meme Classifier and Sarcasm Detector trained and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2HsfrOCYntN",
        "outputId": "4e7bed0f-8b52-4e3b-da7b-19468147a554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-04 09:33:08.339988: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-04 09:33:08.357997: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-04 09:33:08.379134: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-04 09:33:08.385584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-04 09:33:08.400809: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-04 09:33:09.574303: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using device: cuda\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/content/HateMeme/src/test.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sarcasm_detector.load_state_dict(torch.load('models/roberta_sarcasm_detector.pth', map_location=device))\n",
            "/content/HateMeme/src/test.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  classifier.load_state_dict(torch.load('models/hateful_meme_classifier.pth', map_location=device))\n",
            "Test Set Evaluation | Accuracy: 0.5329 | Precision: 0.3978 | Recall: 0.5869 | F1-Score: 0.4742\n"
          ]
        }
      ]
    }
  ]
}